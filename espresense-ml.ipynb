{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from influxdb import InfluxDBClient\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dateutil.parser import parse\n",
    "from dateutil import tz\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set(font_scale=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfluxDB:\n",
    "    def __init__(self, url: str, port: int, username: str, password: str,\n",
    "                 basestations: list, beacon: str, classification: str,\n",
    "                 startdatetime: str = None, enddatetime: str = None):\n",
    "        self.client = InfluxDBClient(url, port, username, password)\n",
    "        self.basestations = basestations\n",
    "        self.beacon = beacon\n",
    "        self.classification = classification\n",
    "        self.timefilter = '1=1'\n",
    "        self.timefilter += f\"\\n\\t\\tAND time >= '{InfluxDB.convert_to_rfc3339(startdatetime)}'\" if startdatetime else ''\n",
    "        self.timefilter += f\"\\n\\t\\tAND time <= '{InfluxDB.convert_to_rfc3339(enddatetime)}'\" if enddatetime else ''\n",
    "\n",
    "    @property\n",
    "    def df_basestation_beacon_values(self):\n",
    "        where = ''.join([f\"\\n\\t\\t    OR entity_id = 'mqtt_{self.beacon}_{basestation}_raw'\" for basestation in self.basestations])\n",
    "        query = f'''\n",
    "            SELECT friendly_name_str as basestation, value as distance\n",
    "            FROM homeassistant.autogen.m\n",
    "            WHERE {self.timefilter}\n",
    "                AND (\n",
    "                    1<>1 {where}\n",
    "                )\n",
    "        '''\n",
    "        df = pd.DataFrame(self.client.query(query).get_points())\n",
    "        df.time = pd.to_datetime(df.time)\n",
    "        return df\n",
    "\n",
    "    @property\n",
    "    def df_classifications(self):\n",
    "        query = f'''\n",
    "            SELECT state as y\n",
    "            FROM homeassistant.autogen.state\n",
    "            WHERE {self.timefilter}\n",
    "                AND entity_id = '{self.classification}'\n",
    "        '''\n",
    "        df = pd.DataFrame(self.client.query(query).get_points())\n",
    "        df.time = pd.to_datetime(df.time)\n",
    "        return df\n",
    "\n",
    "    def get_Xy(self):\n",
    "        self.df = (\n",
    "            pd.concat([self.df_basestation_beacon_values, self.df_classifications], axis=0)\n",
    "            .pivot(index=['time', 'y'], columns='basestation', values='distance')\n",
    "            .fillna(method='ffill')\n",
    "            .reset_index('y')\n",
    "            .fillna(method='ffill')\n",
    "            .drop(np.nan, axis=1)\n",
    "            .dropna()\n",
    "            .query('y != \"None\"')\n",
    "        )\n",
    "        self.X = self.df.drop('y', axis=1)\n",
    "        self.y = self.df.y\n",
    "        return self.X, self.y\n",
    "\n",
    "    def show_basestation_strength(self):\n",
    "        fig, ax = plt.subplots(3, figsize=(10, 3), sharex=True, sharey=True)\n",
    "        data = self.df_basestation_beacon_values\n",
    "        for i, basestation in enumerate(data.basestation.unique()):\n",
    "            sns.lineplot(\n",
    "                data=data.loc[data.basestation == basestation],\n",
    "                x='time', y='distance',\n",
    "                linewidth=0.5, ax=ax[i]\n",
    "            ).set_title(basestation)\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_to_rfc3339(date_string):\n",
    "        dt = parse(date_string)\n",
    "        dt = dt.astimezone(tz.UTC)\n",
    "        return dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "influx = InfluxDB(\n",
    "    url='192.168.50.134',\n",
    "    port=8086,\n",
    "    username='homeassistant',\n",
    "    password='homeassistant',\n",
    "    basestations=['office', 'livingroom', 'bedroomjk'],\n",
    "    beacon='iphonejd',\n",
    "    classification='jd_iphone_room_training_data',\n",
    "    startdatetime='2023-07-17T21:51:00',\n",
    ")\n",
    "\n",
    "X, y = influx.get_Xy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.56547619 0.62874251 0.5988024  0.62275449 0.5748503 ]\n",
      "Mean cross-validation accuracy: 0.5981251782149986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Define pipeline\n",
    "pipeline = make_pipeline(\n",
    "    PolynomialFeatures(degree=2),\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=100000, class_weight='balanced')\n",
    ")\n",
    "\n",
    "# Use cross_val_score for StratifiedKFold cross-validation\n",
    "scores = cross_val_score(pipeline, X, y, cv=StratifiedKFold(n_splits=5))\n",
    "\n",
    "# Print metrics\n",
    "print(\"Cross-validation accuracy scores:\", scores)\n",
    "print(\"Mean cross-validation accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6363636363636364\n",
      "[[11  0  3  0  0  0  0  0  0  0  0]\n",
      " [ 0 21  0  0  0  0  5  0  0  0  0]\n",
      " [ 3  0  9  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  5  2  2  0  6  0  0  5]\n",
      " [ 0  0  0  1 11  4  1  0  0  5  5]\n",
      " [ 0  0  0  0  0  8  1  0  5  0  2]\n",
      " [ 4  4  0  0  0  0  9  0  1  0  0]\n",
      " [ 0  0  0  1  0  0  0  6  0  0  3]\n",
      " [ 0  0  0  0  0  6  1  0 33  0  0]\n",
      " [ 0  0  0  0  3  0  0  0  0 10  0]\n",
      " [ 0  0  0  0  0  2  0  0  0  0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   BedroomCC       0.61      0.79      0.69        14\n",
      "   BedroomJK       0.84      0.81      0.82        26\n",
      "    BedroomS       0.75      0.69      0.72        13\n",
      "  DiningRoom       0.71      0.25      0.37        20\n",
      "    Hallway0       0.69      0.41      0.51        27\n",
      "    Hallway1       0.36      0.50      0.42        16\n",
      "    Hallway2       0.50      0.50      0.50        18\n",
      "     Kitchen       0.50      0.60      0.55        10\n",
      "  LivingRoom       0.85      0.82      0.84        40\n",
      "      Office       0.67      0.77      0.71        13\n",
      "    Playroom       0.40      0.83      0.54        12\n",
      "\n",
      "    accuracy                           0.64       209\n",
      "   macro avg       0.63      0.63      0.61       209\n",
      "weighted avg       0.67      0.64      0.63       209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Fit and score\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(pipeline.score(X_test, y_test))\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print metrics\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6650717703349283\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X, y)\n",
    "print(pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected with result code 0\n",
      "['LivingRoom']\n",
      "['Office']\n",
      "['Office']\n",
      "['Office']\n",
      "['Office']\n",
      "['Office']\n",
      "['Office']\n",
      "['Office']\n",
      "['Office']\n",
      "['Office']\n",
      "['Office']\n",
      "['Office']\n",
      "['Office']\n",
      "['Hallway0']\n",
      "['Office']\n",
      "['Hallway0']\n",
      "['Hallway0']\n",
      "['Hallway0']\n",
      "['Hallway0']\n",
      "['Hallway0']\n",
      "['Playroom']\n",
      "['Playroom']\n",
      "['Playroom']\n",
      "['Playroom']\n",
      "['Kitchen']\n",
      "['Playroom']\n",
      "['Playroom']\n",
      "['Playroom']\n",
      "['Playroom']\n",
      "['Playroom']\n",
      "['Playroom']\n",
      "['Hallway0']\n",
      "['Office']\n",
      "['Office']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m client\u001b[39m.\u001b[39mon_message \u001b[39m=\u001b[39m on_message\n\u001b[1;32m     30\u001b[0m client\u001b[39m.\u001b[39mconnect(\u001b[39m\"\u001b[39m\u001b[39m192.168.50.134\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1883\u001b[39m, \u001b[39m60\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m client\u001b[39m.\u001b[39;49mloop_forever()\n",
      "File \u001b[0;32m~/git/ESPresense-ml/venv/lib64/python3.11/site-packages/paho/mqtt/client.py:1756\u001b[0m, in \u001b[0;36mClient.loop_forever\u001b[0;34m(self, timeout, max_packets, retry_first_connection)\u001b[0m\n\u001b[1;32m   1754\u001b[0m rc \u001b[39m=\u001b[39m MQTT_ERR_SUCCESS\n\u001b[1;32m   1755\u001b[0m \u001b[39mwhile\u001b[39;00m rc \u001b[39m==\u001b[39m MQTT_ERR_SUCCESS:\n\u001b[0;32m-> 1756\u001b[0m     rc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_loop(timeout)\n\u001b[1;32m   1757\u001b[0m     \u001b[39m# We don't need to worry about locking here, because we've\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[39m# either called loop_forever() when in single threaded mode, or\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m     \u001b[39m# in multi threaded mode when loop_stop() has been called and\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     \u001b[39m# so no other threads can access _out_packet or _messages.\u001b[39;00m\n\u001b[1;32m   1761\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_thread_terminate \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1762\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_out_packet) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   1763\u001b[0m             \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_out_messages) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n",
      "File \u001b[0;32m~/git/ESPresense-ml/venv/lib64/python3.11/site-packages/paho/mqtt/client.py:1150\u001b[0m, in \u001b[0;36mClient._loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     rlist \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sockpairR]\n\u001b[1;32m   1149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1150\u001b[0m     socklist \u001b[39m=\u001b[39m select\u001b[39m.\u001b[39mselect(rlist, wlist, [], timeout)\n\u001b[1;32m   1151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   1152\u001b[0m     \u001b[39m# Socket isn't correct type, in likelihood connection is lost\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m     \u001b[39mreturn\u001b[39;00m MQTT_ERR_CONN_LOST\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import paho.mqtt.client as mqtt\n",
    "import json\n",
    "\n",
    "verbose = False\n",
    "\n",
    "X_live = {\n",
    "    'espresense/devices/jd_iphone/bedroomjk': 0.,\n",
    "    'espresense/devices/jd_iphone/livingroom': 0.,\n",
    "    'espresense/devices/jd_iphone/office': 0.,\n",
    "}\n",
    "\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    print(\"Connected with result code \"+str(rc))\n",
    "    client.subscribe(\"espresense/devices/jd_iphone/bedroomjk\")\n",
    "    client.subscribe(\"espresense/devices/jd_iphone/office\")\n",
    "    client.subscribe(\"espresense/devices/jd_iphone/livingroom\")\n",
    "\n",
    "def on_message(client, userdata, msg):\n",
    "    data = json.loads(msg.payload)\n",
    "    if 'raw' in data:\n",
    "        X_live[msg.topic] = data['raw']\n",
    "        #x = np.array(list(X_live.values())).reshape(1, -1)\n",
    "        x = pd.DataFrame(X_live.values(), index=['MQTT iPhoneJD BedroomJK Raw', 'MQTT iPhoneJD LivingRoom Raw', 'MQTT iPhoneJD Office Raw']).T\n",
    "        print(pipeline.predict(x))\n",
    "\n",
    "client = mqtt.Client()\n",
    "client.username_pw_set(\"mqtt-user\", \"vlmSDF543\")\n",
    "client.on_connect = on_connect\n",
    "client.on_message = on_message\n",
    "client.connect(\"192.168.50.134\", 1883, 60)\n",
    "client.loop_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
